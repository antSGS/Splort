{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e095826-4bae-4da6-a315-cac3b85f0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import urllib3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9456e-8901-4844-addc-ace62d412fb9",
   "metadata": {},
   "source": [
    "## Getting data from Strava's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a46f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T09:41:25.956875Z",
     "start_time": "2025-09-08T09:41:25.817918Z"
    }
   },
   "outputs": [],
   "source": [
    "####### CREDENTIALS #######\n",
    "\n",
    "# The activity parsing routine below comes directly from this very usefull code --> https://github.com/franchyze923/Code_From_Tutorials/tree/master/Strava_Api. \n",
    "# Mod to prevent from leaking credentials --> using a .env file \n",
    "\n",
    "####### What should I put in my .env file? ########\n",
    "\n",
    "# CLIENT_ID=\"YourID\"\n",
    "# CLIENT_SECRET='YourSecretToken'\n",
    "# REFRESH_TOKEN='YourRefreshToken'\n",
    "\n",
    "####### How to get this ? ########\n",
    "\n",
    "# Again, use the excellent work of the aforementionned author --> https://towardsdatascience.com/using-the-strava-api-and-pandas-to-explore-your-activity-data-d94901d9bfde/\n",
    "\n",
    "\n",
    "\n",
    "auth_url = \"https://www.strava.com/oauth/token\"\n",
    "activites_url = \"https://www.strava.com/api/v3/athlete/activities\"\n",
    "\n",
    "payload = {\n",
    "    'client_id': os.getenv('CLIENT_ID'),\n",
    "    'client_secret': os.getenv('CLIENT_SECRET'),\n",
    "    'refresh_token': os.getenv('REFRESH_TOKEN'),\n",
    "    'grant_type': \"refresh_token\",\n",
    "    'f': 'json'\n",
    "}\n",
    "\n",
    "print(\"Requesting Token...\\n\")\n",
    "res = requests.post(auth_url, data=payload, verify=False)\n",
    "access_token = res.json()['access_token']\n",
    "print(\"Access Token Granted!\\n\")\n",
    "\n",
    "header = {'Authorization': 'Bearer ' + access_token}\n",
    "param = {'per_page': 200, 'page': 10}\n",
    "\n",
    "# The first loop, request_page_number will be set to one, so it requests the first page. Increment this number after\n",
    "# each request, so the next time we request the second page, then third, and so on...\n",
    "request_page_num = 1\n",
    "all_activities = []\n",
    "\n",
    "\n",
    "while True:\n",
    "    param = {'per_page': 200, 'page': request_page_num}\n",
    "    # initial request, where we request the first page of activities\n",
    "    my_dataset = requests.get(activites_url, headers=header, params=param).json()\n",
    "\n",
    "    # check the response to make sure it is not empty. If it is empty, that means there is no more data left. So if you have\n",
    "    # 1000 activities, on the 6th request, where we request page 6, there would be no more data left, so we will break out of the loop\n",
    "    if len(my_dataset) == 0:\n",
    "        print(\"breaking out of while loop because the response is zero, which means there must be no more activities\")\n",
    "        break\n",
    "\n",
    "    # if the all_activities list is already populated, that means we want to add additional data to it via extend.\n",
    "    if all_activities:\n",
    "        print(\"all_activities is populated\")\n",
    "        all_activities.extend(my_dataset)\n",
    "\n",
    "    # if the all_activities is empty, this is the first time adding data so we just set it equal to my_dataset\n",
    "    else:\n",
    "        print(\"all_activities is NOT populated\")\n",
    "        all_activities = my_dataset\n",
    "\n",
    "    request_page_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328b5fe-2ffd-4fb9-a3b8-c36afd735a8f",
   "metadata": {},
   "source": [
    "## Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c451ad5b343e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T09:41:25.972139Z",
     "start_time": "2025-02-28T18:40:47.100249Z"
    }
   },
   "outputs": [],
   "source": [
    "# using a df for better handling\n",
    "all_activities=pd.DataFrame(all_activities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9e694cfbc79bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T09:41:25.973273Z",
     "start_time": "2025-02-28T18:41:26.187426Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting individual sport types\n",
    "sport_types=all_activities.sport_type.unique()\n",
    "sport_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983986f-3bd2-4680-b5d9-79437a270997",
   "metadata": {},
   "source": [
    "## Exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6a40f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T09:41:25.974175Z",
     "start_time": "2025-02-28T18:43:39.916577Z"
    }
   },
   "outputs": [],
   "source": [
    "### Let's plot\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import polyline\n",
    "\n",
    "colors = px.colors.qualitative.Alphabet\n",
    "if len(sport_types) > len(colors):\n",
    "    raise ValueError(\"Not enough colors in the chosen palette for the number of sport types.\")\n",
    "\n",
    "custom_color_mapping = dict(zip(sport_types, colors[:len(sport_types)]))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for index, row in all_activities.iterrows():\n",
    "    polyline_code = row['map']['summary_polyline']\n",
    "    sport_type = row['sport_type']\n",
    "    coordinates = polyline.decode(polyline_code, 5)\n",
    "    longitudes = [coordinate[1] for coordinate in coordinates]\n",
    "    latitudes = [coordinate[0] for coordinate in coordinates]\n",
    "    \n",
    "    color = custom_color_mapping[sport_type]\n",
    "\n",
    "    # Add trace for each polyline\n",
    "    fig.add_trace(go.Scattermap(\n",
    "        lon=longitudes,\n",
    "        lat=latitudes,\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=1, color=color),\n",
    "        opacity=0.7,\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "\n",
    "# Update layout to enable the map display\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    map_style='carto-darkmatter',\n",
    ")\n",
    "\n",
    "# Show figure\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3b526-be57-4fd6-b48d-e172516abc69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fd206-aba3-40ae-a5e6-b98ca4bf80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_activities['time'] = pd.to_datetime(all_activities.start_date)\n",
    "\n",
    "all_activities['year'] = all_activities['time'].dt.year\n",
    "all_activities['day'] = all_activities['time'].dt.day\n",
    "\n",
    "\n",
    "sports = all_activities['type'].unique()\n",
    "years = all_activities['year'].unique()\n",
    "\n",
    "\n",
    "colormap = plt.get_cmap('tab10')  \n",
    "year_colors = {year: colormap(i) for i, year in enumerate(years)}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(len(sports), 1, figsize=(10, 5 * len(sports)), sharex=True)\n",
    "\n",
    "if len(sports) == 1:\n",
    "    axes = [axes]  \n",
    "\n",
    "for ax, sport in zip(axes, sports):\n",
    "    for year, year_data in all_activities[all_activities['type'] == sport].groupby('year'):\n",
    "        year_data = year_data.sort_values('time')  \n",
    "        year_data['cumulative_distance'] = year_data['distance'].cumsum()  \n",
    "        year_data['day_of_year'] = year_data['time'].dt.dayofyear\n",
    "        \n",
    "        ax.plot(year_data['day_of_year'], year_data['cumulative_distance'], \n",
    "                label=f\"{year}\", color=year_colors[year], marker='o')\n",
    "\n",
    "    ax.set_title(f\"Cumulative Distance for {sport}\")\n",
    "    ax.set_ylabel(\"Cumulative Distance\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "# Set common x-label\n",
    "plt.xlabel(\"Day of the Year\")\n",
    "plt.suptitle(\"Cumulative Distance per Sport per Year\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0e111-3f28-467e-a94c-c5a012702342",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_activities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d3a88f-f0fc-4aa7-bded-71fed3788ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
